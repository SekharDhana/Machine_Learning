{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYmKuVFgSnf2",
        "outputId": "7e97fe2c-c4ff-44f5-cee8-c2ae2fb937cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy before quantization: 0.9\n",
            "Size before quantization: 48\n",
            "Accuracy after quantization: 0.6333333333333333\n",
            "Size after quantization: 48\n",
            "Size difference: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (120). n_quantiles is set to n_samples.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "import sys\n",
        "\n",
        "# Load the iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Multinomial Naive Bayes model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model's accuracy on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy_before = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy before quantization: {accuracy_before}\")\n",
        "\n",
        "# Get the size of the model before quantization\n",
        "size_before = sys.getsizeof(model)\n",
        "print(f\"Size before quantization: {size_before}\")\n",
        "\n",
        "# Quantize the model using the QuantileTransformer\n",
        "qt = QuantileTransformer()\n",
        "X_train_quantized = qt.fit_transform(X_train)\n",
        "X_test_quantized = qt.transform(X_test)\n",
        "model_quantized = MultinomialNB()\n",
        "model_quantized.fit(X_train_quantized, y_train)\n",
        "\n",
        "# Evaluate the quantized model's accuracy on the test set\n",
        "y_pred_quantized = model_quantized.predict(X_test_quantized)\n",
        "accuracy_after = accuracy_score(y_test, y_pred_quantized)\n",
        "print(f\"Accuracy after quantization: {accuracy_after}\")\n",
        "\n",
        "# Get the size of the model after quantization\n",
        "size_after = sys.getsizeof(model_quantized)\n",
        "print(f\"Size after quantization: {size_after}\")\n",
        "\n",
        "# Print the size difference\n",
        "size_difference = size_before - size_after\n",
        "print(f\"Size difference: {size_difference}\")\n",
        "\n",
        "\n",
        "\n",
        "import pickle\n",
        "\n",
        "# Save the original model using pickle\n",
        "with open('original_model.pickle', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "# Load the original model from pickle\n",
        "with open('original_model.pickle', 'rb') as f:\n",
        "    model_loaded = pickle.load(f)\n",
        "\n",
        "# Save the quantized model using pickle\n",
        "with open('quantized_model.pickle', 'wb') as f:\n",
        "    pickle.dump(model_quantized, f)\n",
        "\n",
        "# Load the quantized model from pickle\n",
        "with open('quantized_model.pickle', 'rb') as f:\n",
        "    model_quantized_loaded = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zbJCjjgJSrm6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}