{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "25897d15061d4b558b0197c07dba37dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5b2d21bd1174eacbad4a2ccca2e6cd7",
              "IPY_MODEL_6452a9c2e09a40feac0971095e95e250",
              "IPY_MODEL_f7d022ec0a164d848c0ec8a7a6cf019d"
            ],
            "layout": "IPY_MODEL_7dd521616bae4d0bad77727c04b6a96f"
          }
        },
        "e5b2d21bd1174eacbad4a2ccca2e6cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5147156d06464b0d91782a5d51dfc7f5",
            "placeholder": "​",
            "style": "IPY_MODEL_84e070e8ab3a4944b2f619ab80255041",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "6452a9c2e09a40feac0971095e95e250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58fa7ede80ca47f591b38ccc246abd2d",
            "max": 222,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6821f430a9c54e13b61a2573226d2b57",
            "value": 222
          }
        },
        "f7d022ec0a164d848c0ec8a7a6cf019d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4540070d5bae4c7ea22e0bf134c5a0e2",
            "placeholder": "​",
            "style": "IPY_MODEL_1a9caae9b24c4a5c839b2fe44df8f75d",
            "value": " 222/222 [00:00&lt;00:00, 8.53kB/s]"
          }
        },
        "7dd521616bae4d0bad77727c04b6a96f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5147156d06464b0d91782a5d51dfc7f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84e070e8ab3a4944b2f619ab80255041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58fa7ede80ca47f591b38ccc246abd2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6821f430a9c54e13b61a2573226d2b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4540070d5bae4c7ea22e0bf134c5a0e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a9caae9b24c4a5c839b2fe44df8f75d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e98318f040c3486cbbcf67460ddcddfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a993cbd076a5443faf9a157f036d2ba9",
              "IPY_MODEL_a7f2d5c0b80540b8a15af42eef0548a0",
              "IPY_MODEL_13b205452af649b78b2291e940ed8b21"
            ],
            "layout": "IPY_MODEL_97f21270e9d943718a430963a81149eb"
          }
        },
        "a993cbd076a5443faf9a157f036d2ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_256ccb3625d445e4b665465e0f547270",
            "placeholder": "​",
            "style": "IPY_MODEL_fa279731661249329626fa53d8265344",
            "value": "Downloading tokenizer.json: 100%"
          }
        },
        "a7f2d5c0b80540b8a15af42eef0548a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2daeba0b4c644a56b6613b78ba63f09f",
            "max": 14500438,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_213bef9e7c1045709a01228ac0a91561",
            "value": 14500438
          }
        },
        "13b205452af649b78b2291e940ed8b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fa411c2d2764942844bb35dd453f18f",
            "placeholder": "​",
            "style": "IPY_MODEL_1b49bfb2a8dd4f018d26da288e0b566b",
            "value": " 14.5M/14.5M [00:00&lt;00:00, 52.9MB/s]"
          }
        },
        "97f21270e9d943718a430963a81149eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "256ccb3625d445e4b665465e0f547270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa279731661249329626fa53d8265344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2daeba0b4c644a56b6613b78ba63f09f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "213bef9e7c1045709a01228ac0a91561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7fa411c2d2764942844bb35dd453f18f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b49bfb2a8dd4f018d26da288e0b566b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05ee548345fc44f1bed53bdebab6cc8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb79a9be5fcf4bf1a5c849bc938f3190",
              "IPY_MODEL_c5ab20c19f0a4a1197c6609c66c4b5ea",
              "IPY_MODEL_98fc6e206c2b472e9acfd581e2bd820a"
            ],
            "layout": "IPY_MODEL_b7d7e08afc044812b4ce01efb2214dfb"
          }
        },
        "eb79a9be5fcf4bf1a5c849bc938f3190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d42b5dee89c4d3ab10e4307ae6277a5",
            "placeholder": "​",
            "style": "IPY_MODEL_4cf4f15883924a08a731a43b1f509f37",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "c5ab20c19f0a4a1197c6609c66c4b5ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d759170d7c5343d98905cae418cdba07",
            "max": 85,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7260b4b5e0da48f180abd9a047c0dc12",
            "value": 85
          }
        },
        "98fc6e206c2b472e9acfd581e2bd820a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e7ad7d90c2c4b81ba91dd3566f030d4",
            "placeholder": "​",
            "style": "IPY_MODEL_df8854dbd4974160969c8b15990f33a1",
            "value": " 85.0/85.0 [00:00&lt;00:00, 3.64kB/s]"
          }
        },
        "b7d7e08afc044812b4ce01efb2214dfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d42b5dee89c4d3ab10e4307ae6277a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cf4f15883924a08a731a43b1f509f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d759170d7c5343d98905cae418cdba07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7260b4b5e0da48f180abd9a047c0dc12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e7ad7d90c2c4b81ba91dd3566f030d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df8854dbd4974160969c8b15990f33a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df721daaf54d48eeb107d0799606f07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2938ebc1fd04468b83d77a0540385d81",
              "IPY_MODEL_c478eac246594169a483bf22df84b5a1",
              "IPY_MODEL_ecd6a7cbc4c743999fdab5178ca23361"
            ],
            "layout": "IPY_MODEL_2557e139501848e387d73106b9c66d74"
          }
        },
        "2938ebc1fd04468b83d77a0540385d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd8d30441f4b42e894a20457b9c4cba9",
            "placeholder": "​",
            "style": "IPY_MODEL_98f8bc6087e241fa815737acdec4d347",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "c478eac246594169a483bf22df84b5a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffb3dfb06cdb45c6894c2861ba5f8dca",
            "max": 715,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59c019a745994b1cb3bd0dd5ece90b6f",
            "value": 715
          }
        },
        "ecd6a7cbc4c743999fdab5178ca23361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_908e051e80ae42deaf1901b2ed283a29",
            "placeholder": "​",
            "style": "IPY_MODEL_38ee0d5f6074417681636697fa62a3b3",
            "value": " 715/715 [00:00&lt;00:00, 41.7kB/s]"
          }
        },
        "2557e139501848e387d73106b9c66d74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd8d30441f4b42e894a20457b9c4cba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f8bc6087e241fa815737acdec4d347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffb3dfb06cdb45c6894c2861ba5f8dca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59c019a745994b1cb3bd0dd5ece90b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "908e051e80ae42deaf1901b2ed283a29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38ee0d5f6074417681636697fa62a3b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "020f59416b17415fb71872f505870e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34e4a67c852f4a60aae4b14d813a689e",
              "IPY_MODEL_c4e4b11c0f994e65bde5c7524a444827",
              "IPY_MODEL_87af62f61f4d499d967d9e5e650c3fb5"
            ],
            "layout": "IPY_MODEL_4d393c87034341d59eb872cd4e97c439"
          }
        },
        "34e4a67c852f4a60aae4b14d813a689e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de75e37b9198410eb7f55c6a34c776da",
            "placeholder": "​",
            "style": "IPY_MODEL_84198451569b4351a579ed94e7917d82",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "c4e4b11c0f994e65bde5c7524a444827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c41e57bea367441f9b20d6a42b461b59",
            "max": 3444848602,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d78f74476814b85974fa3284384d8e2",
            "value": 3444848602
          }
        },
        "87af62f61f4d499d967d9e5e650c3fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fda90a8c1c9f4e2997d05f88d8c1402a",
            "placeholder": "​",
            "style": "IPY_MODEL_dd844f60b43e4d10a4150959dffd46af",
            "value": " 3.44G/3.44G [00:41&lt;00:00, 164MB/s]"
          }
        },
        "4d393c87034341d59eb872cd4e97c439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de75e37b9198410eb7f55c6a34c776da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84198451569b4351a579ed94e7917d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c41e57bea367441f9b20d6a42b461b59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d78f74476814b85974fa3284384d8e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fda90a8c1c9f4e2997d05f88d8c1402a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd844f60b43e4d10a4150959dffd46af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX0xfUSykZYl"
      },
      "outputs": [],
      "source": [
        "# Installing packages\n",
        "\n",
        "!pip install langchain openai transformers tiktoken faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Prompt\n",
        "\n",
        "```markdown\n",
        "BasePromptTemplate --> PipelinePromptTemplate\n",
        "                       StringPromptTemplate --> PromptTemplate\n",
        "                                                FewShotPromptTemplate\n",
        "                                                FewShotPromptWithTemplates\n",
        "                       BaseChatPromptTemplate --> AutoGPTPrompt\n",
        "                                                  ChatPromptTemplate --> AgentScratchPadChatPromptTemplate\n",
        "\n",
        "\n",
        "\n",
        "BaseMessagePromptTemplate --> MessagesPlaceholder\n",
        "                              BaseStringMessagePromptTemplate --> ChatMessagePromptTemplate\n",
        "                                                                  HumanMessagePromptTemplate\n",
        "                                                                  AIMessagePromptTemplate\n",
        "                                                                  SystemMessagePromptTemplate\n",
        "\n",
        "PromptValue --> StringPromptValue\n",
        "                ChatPromptValue\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "vBRCS9TEkkq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PromptTemplate\n"
      ],
      "metadata": {
        "id": "sydFLfFFzuCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "from langchain.prompts.prompt import PromptTemplate"
      ],
      "metadata": {
        "id": "ox94CjEWk84n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_template = PromptTemplate(\n",
        "    input_variables= ['cuisine'],\n",
        "    template=\"i want to open a {cuisine} restaurant. sugget me a good name\"\n",
        ")\n",
        "\n",
        "print(my_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JmBQ4d8nqpC",
        "outputId": "05bd7ff5-4761-4c03-9695-e328748af45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['cuisine'] template='i want to open a {cuisine} restaurant. sugget me a good name'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PromptTemplate.format(my_template, cuisine=\"india\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Xh5k7nQNqouT",
        "outputId": "f0ae057c-5377-4725-99d8-bbcea975a387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i want to open a india restaurant. sugget me a good name'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_template_2 = PromptTemplate(\n",
        "    input_variables= ['cuisine', 'location'],\n",
        "    template= \"i want to open a {cuisine} restaurant in {location}. suggest me a good name\"\n",
        ")\n",
        "print(PromptTemplate.format(my_template_2, cuisine=\"Mexican\", location=\"Vizag\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD7CVzVrrN67",
        "outputId": "b6ffa8dd-fd91-4680-a33a-cc44e509db48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i want to open a Mexican restaurant in Vizag. suggest me a good name\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Au5V4Qwt0X8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FewShotPromptTemplate"
      ],
      "metadata": {
        "id": "idqXobbk0Yy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class langchain.prompts.few_shot.FewShotPromptTemplate\n",
        "\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate"
      ],
      "metadata": {
        "id": "aPraDQ2BvQ4f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {   \"question\": \"When was the founder of craigslist born?\",\n",
        "        \"answer\": \"December 6, 1952\"\n",
        "     },\n",
        "    {\n",
        "        \"question\": \"Who was the maternal grandfather of George Washington?\",\n",
        "        \"answer\": \"Joseph Ball\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Are both the directors of Jaws and Casino Royale from the same country?\",\n",
        "        \"answer\": \"No\"\n",
        "    }\n",
        "]\n",
        "\n",
        "qa_template = PromptTemplate(\n",
        "    input_variables= [\"question\", \"answer\"],\n",
        "    template= \"Question: {question}\\nAnswer: {answer}\"\n",
        ")\n",
        "\n",
        "\n",
        "few_shot_template = FewShotPromptTemplate(\n",
        "    input_variables= [\"question\"],\n",
        "    example_prompt = qa_template,\n",
        "    prefix = \"please answer the following question based on these examples:\\n\\nQuestion: {question}\",\n",
        "    suffix = \"\\n\\nAnswer: \",\n",
        "    examples= examples\n",
        ")\n",
        "\n",
        "my_prompt = few_shot_template.format(question=\"who is the prime minister of india?\")\n",
        "\n",
        "print(my_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICBFT7gs0_hG",
        "outputId": "cd961bf6-fcd6-4e61-901a-1ebe83686322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "please answer the following question based on these examples:\n",
            "\n",
            "Question: who is the prime minister of india?\n",
            "\n",
            "Question: When was the founder of craigslist born?\n",
            "Answer: December 6, 1952\n",
            "\n",
            "Question: Who was the maternal grandfather of George Washington?\n",
            "Answer: Joseph Ball\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "Answer: No\n",
            "\n",
            "\n",
            "\n",
            "Answer: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langchain.llms import OpenAI\n",
        "from secret_key import openapi_key, serp_key, huggingface_key\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = openapi_key\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = huggingface_key"
      ],
      "metadata": {
        "id": "Lzi5eFx60_dd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(verbose=True)\n",
        "name = llm(my_prompt)\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHfzBrp20_ZJ",
        "outputId": "3a083636-d859-47eb-a4ee-f30d622e3886"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Narendra Modi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FXqx750N0_Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FewShotPromptWithTemplates\n",
        "\n",
        "I couldnt find much difference between the **FewShotPromptTemplates** and FewShotPromptWithTemplates if you found it just let me know or fork the branch and create a pull request i will merge it. Thank you."
      ],
      "metadata": {
        "id": "0nAn31uEUGys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Selector"
      ],
      "metadata": {
        "id": "huHvP9ztdmb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Semantic Similarity Example Selector"
      ],
      "metadata": {
        "id": "ikNhTgPBdvII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector, MaxMarginalRelevanceExampleSelector\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "qhx677Qd0_L_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
        "    {\"input\": \"tall\", \"output\": \"short\"},\n",
        "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
        "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
        "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
        "    {\"input\": \"boy\", \"output\": \"king\"},\n",
        "    {\"input\": \"girl\", \"output\": \"queen\"},\n",
        "    {\"input\": \"school\", \"output\": \"student\"},\n",
        "    {\"input\": \"police station\", \"output\": \"police man\"}\n",
        "]\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=['input','output'],\n",
        "    template = \"input:{input}\\noutput:{output}\"\n",
        ")\n",
        "\n",
        "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
        "    examples,\n",
        "    OpenAIEmbeddings(),\n",
        "    FAISS,\n",
        "    k=3\n",
        ")\n",
        "\n",
        "similar_prompts = FewShotPromptTemplate(\n",
        "    example_selector = example_selector,\n",
        "    example_prompt= example_prompt,\n",
        "    prefix = \"give the anotomy of every input\",\n",
        "    suffix = \"Input: {user_input}\\nOutput:\",\n",
        "    input_variables = ['user_input']\n",
        "\n",
        ")\n",
        "\n",
        "mychain = LLMChain(llm=OpenAI(),prompt=similar_prompts,verbose=True)\n",
        "print(mychain.predict(user_input='fire'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od-P-iqAdf6b",
        "outputId": "f87a1bf5-e63e-42b5-fc12-68aa22682fa8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mgive the anotomy of every input\n",
            "\n",
            "input:police station\n",
            "output:police man\n",
            "\n",
            "input:school\n",
            "output:student\n",
            "\n",
            "input:windy\n",
            "output:calm\n",
            "\n",
            "Input: fire\n",
            "Output:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " Smoke\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### maximal marginal relevance (MMR)"
      ],
      "metadata": {
        "id": "9doqppP1tp8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
        "    {\"input\": \"tall\", \"output\": \"short\"},\n",
        "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
        "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
        "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
        "    {\"input\": \"boy\", \"output\": \"king\"},\n",
        "    {\"input\": \"girl\", \"output\": \"queen\"},\n",
        "    {\"input\": \"school\", \"output\": \"student\"},\n",
        "    {\"input\": \"police station\", \"output\": \"police man\"}\n",
        "]\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=['input','output'],\n",
        "    template = \"input:{input}\\noutput:{output}\"\n",
        ")\n",
        "\n",
        "example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
        "    examples,\n",
        "    OpenAIEmbeddings(),\n",
        "    FAISS,\n",
        "    k=3\n",
        ")\n",
        "\n",
        "similar_prompts = FewShotPromptTemplate(\n",
        "    example_selector = example_selector,\n",
        "    example_prompt= example_prompt,\n",
        "    prefix = \"give the anotomy of every input\",\n",
        "    suffix = \"Input: {user_input}\\nOutput:\",\n",
        "    input_variables = ['user_input']\n",
        "\n",
        ")\n",
        "\n",
        "mychain = LLMChain(llm=OpenAI(),prompt=similar_prompts,verbose=True)\n",
        "print(mychain.predict(user_input='fire'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAisA8Psdf31",
        "outputId": "1cef1dca-ac61-432c-c09e-e1202e5c49c1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mgive the anotomy of every input\n",
            "\n",
            "input:police station\n",
            "output:police man\n",
            "\n",
            "input:energetic\n",
            "output:lethargic\n",
            "\n",
            "input:girl\n",
            "output:queen\n",
            "\n",
            "Input: fire\n",
            "Output:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            " Smoke\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### n-gram overlap\n",
        "\n",
        "I dont want to cover this since its typical n-gram approach"
      ],
      "metadata": {
        "id": "vCP4ytXOxbnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### length\n",
        "\n",
        "his example selector selects which examples to use based on length. This is useful when you are worried about constructing a prompt that will go over the length of the context window. For longer inputs, it will select fewer examples to include, while for shorter inputs it will select more."
      ],
      "metadata": {
        "id": "fqHU5dD1xmbW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q-2nph72x7yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OutputParser"
      ],
      "metadata": {
        "id": "s3Ifx2Zd6E5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### StructuredOutputParser"
      ],
      "metadata": {
        "id": "SjebWcUe6Ln2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import ResponseSchema, StructuredOutputParser"
      ],
      "metadata": {
        "id": "ncbU6BOlx7p6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ress = [ResponseSchema(name=\"bad string\", description=\"This is a poorly formated user input string\"),\n",
        "        ResponseSchema(name=\"good string\", description=\"This is your reponse, a reformatted response\")]\n",
        "\n",
        "output = StructuredOutputParser.from_response_schemas(Ress)\n",
        "format_instruction = output.get_format_instructions()\n",
        "print(format_instruction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z500aqjdf1N",
        "outputId": "dde407f0-52a1-4c6b-ce1b-9f0f71d1a125"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"bad string\": string  // This is a poorly formated user input string\n",
            "\t\"good string\": string  // This is your reponse, a reformatted response\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "you might be given a poorly formated string from a user.\n",
        "\n",
        "Reformat it and make sure all the words are spelled correctly including country, state and city names.\n",
        "\n",
        "{format_instruction}\n",
        "\n",
        "User Input: {user_input}\n",
        "\n",
        "your response:\n",
        "\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=['user_input'],\n",
        "    partial_variables={\"format_instruction\": format_instruction},\n",
        "    template = template\n",
        ")\n",
        "\n",
        "mychain = LLMChain(llm=OpenAI(),prompt=prompt,verbose=True)\n",
        "print(mychain.predict(user_input=\"thr shd be some user accptance test that we need to do\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIH8e3YedfyN",
        "outputId": "8bd71787-1ab9-4481-d300-5ea397d2016f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "you might be given a poorly formated string from a user.\n",
            "\n",
            "Reformat it and make sure all the words are spelled correctly including country, state and city names.\n",
            "\n",
            "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"bad string\": string  // This is a poorly formated user input string\n",
            "\t\"good string\": string  // This is your reponse, a reformatted response\n",
            "}\n",
            "```\n",
            "\n",
            "User Input: thr shd be some user accptance test that we need to do\n",
            "\n",
            "your response: \n",
            "\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "```json\n",
            "{\n",
            "\t\"bad string\": \"thr shd be some user accptance test that we need to do\",\n",
            "\t\"good string\": \"There should be some user acceptance tests that we need to do\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SrxCkn199AaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vyzDb9_r9AW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vz96ryoY9AUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AsvfsKU69AJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoGPT"
      ],
      "metadata": {
        "id": "h1n5uB-sW0NN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Under Construction......!!!!!!!!!!!!\n"
      ],
      "metadata": {
        "id": "NH7_o2l9W3xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OFbAEplKPt36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Memory"
      ],
      "metadata": {
        "id": "iPY_aI5PPucO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat Messages"
      ],
      "metadata": {
        "id": "BNJudFfkQQ0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ChatMessageHistory"
      ],
      "metadata": {
        "id": "ZHKt0tYKPtcI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = ChatMessageHistory()\n",
        "\n",
        "history.add_user_message(\"hi\")\n",
        "\n",
        "history.add_user_message(\"what is your name\")\n",
        "\n",
        "history.add_ai_message(\"i am good thanks for asking\")"
      ],
      "metadata": {
        "id": "gvXTnMZpP4kq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5CAVll2P4hw",
        "outputId": "d1c84f31-e3f1-4b46-c19e-87eff1ff0a5b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatMessageHistory(messages=[HumanMessage(content='hi'), HumanMessage(content='what is your name'), AIMessage(content='i am good thanks for asking')])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MemoryTypes"
      ],
      "metadata": {
        "id": "nB6WIoR0fG9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conversation Buffer"
      ],
      "metadata": {
        "id": "6HPvdSZVfJuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain"
      ],
      "metadata": {
        "id": "zHJrM47iP4fE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mychain = ConversationChain(\n",
        "    memory = ConversationBufferMemory(),\n",
        "    verbose = True,\n",
        "    llm = OpenAI()\n",
        ")\n",
        "\n",
        "mychain.predict(input=\"hi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "KLH9tKkcfP66",
        "outputId": "c11b896c-8ba0-453b-ec90-d86230f2b56c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: hi\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hi there! It's nice to meet you. How can I help you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mychain.predict(input = \"my name is sekhar, i want to know who is prime minister of india\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "HPBjiOTPfP4U",
        "outputId": "85720f6e-94bd-4485-bc57-c6a2ab685a42"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: hi\n",
            "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
            "Human: my name is sekhar, i want to know who is prime minister of india\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The current Prime Minister of India is Narendra Modi. He has been in office since 2014. Is there anything else I can help you with today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mychain.predict(input=\"what is my name\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "qynCFzHyfP1n",
        "outputId": "9cfe7a82-f8b4-4297-d944-90ff9e2f5968"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: hi\n",
            "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
            "Human: my name is sekhar, i want to know who is prime minister of india\n",
            "AI:  The current Prime Minister of India is Narendra Modi. He has been in office since 2014. Is there anything else I can help you with today?\n",
            "Human: what is my name\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  You said your name is Sekhar. Is that correct?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mychain.memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y63bvTYpfPzR",
        "outputId": "0b1bc0c1-e6b8-402b-e1f7-8a41d5e55117"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': \"Human: hi\\nAI:  Hi there! It's nice to meet you. How can I help you today?\\nHuman: my name is sekhar, i want to know who is prime minister of india\\nAI:  The current Prime Minister of India is Narendra Modi. He has been in office since 2014. Is there anything else I can help you with today?\\nHuman: what is my name\\nAI:   You said your name is Sekhar. Is that correct?\"}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conversation Buffer Window"
      ],
      "metadata": {
        "id": "sdpy4WcHjNIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "ZCGCNEXvfPw-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_my_chain = ConversationChain(\n",
        "    memory = ConversationBufferWindowMemory(k=2),\n",
        "    llm = OpenAI(),\n",
        "    verbose = True\n",
        ")\n",
        "\n",
        "_my_chain.predict(input = \"hi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "5SMeJbGRjRo4",
        "outputId": "f6c189d9-ff8b-47bc-df2a-c5a616d9bc7b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: hi\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hi there! It's nice to meet you. How can I help you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_my_chain.predict(input = \"my name is sekhar\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "pYEYhl6jjRkx",
        "outputId": "f499314b-a39e-49ea-d087-177328e29af8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: hi\n",
            "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
            "Human: my name is sekhar\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Nice to meet you Sekhar! What can I do for you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_my_chain.predict(input = \"who is the pm of india\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "Xr4cJ-OXjRiS",
        "outputId": "06aa1761-6ba9-4967-ba91-420a48dc02e7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: hi\n",
            "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
            "Human: my name is sekhar\n",
            "AI:  Nice to meet you Sekhar! What can I do for you today?\n",
            "Human: who is the pm of india\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The Prime Minister of India is Narendra Modi. He was sworn in as the Prime Minister on May 30, 2014.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_my_chain.predict(input = \"what is the time now\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "sllzNgLkfPui",
        "outputId": "221abdf6-8618-4ce0-f4bc-f59f98e5ec04"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: my name is sekhar\n",
            "AI:  Nice to meet you Sekhar! What can I do for you today?\n",
            "Human: who is the pm of india\n",
            "AI:  The Prime Minister of India is Narendra Modi. He was sworn in as the Prime Minister on May 30, 2014.\n",
            "Human: what is the time now\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The current time is 8:43 PM.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_my_chain.predict(input = \"what is my name\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "to5P85LWP4cq",
        "outputId": "4e666336-25b7-432d-d4c7-971b3becbace"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: who is the pm of india\n",
            "AI:  The Prime Minister of India is Narendra Modi. He was sworn in as the Prime Minister on May 30, 2014.\n",
            "Human: what is the time now\n",
            "AI:  The current time is 8:43 PM.\n",
            "Human: what is my name\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" I don't know what your name is.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conversation Summary"
      ],
      "metadata": {
        "id": "yMcG_wiJ4hrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.memory import ConversationSummaryMemory\n",
        "llm = OpenAI(temperature=0)\n",
        "conversation_with_summary = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=ConversationSummaryMemory(llm=OpenAI()),\n",
        "    verbose=True\n",
        ")\n",
        "conversation_with_summary.predict(input=\"Hi, what's up?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "RNb0VsvOkhqC",
        "outputId": "eb0f7fa4-8593-4461-e52b-53b735a592b9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi, what's up?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hi there! I'm doing great. I'm currently helping a customer with a technical issue. How about you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary.predict(input=\"i am just learning how you are working thats it.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "BvCxcTuHkhhm",
        "outputId": "d8c44d79-8b16-486b-cc9d-ea97370e71aa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "The human asked the AI what it was doing, and the AI responded that it was helping a customer with a technical issue.\n",
            "Human: i am just learning how you are working thats it.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" I'm helping a customer with a technical issue. I'm troubleshooting the issue and providing them with the best solution. I'm also providing them with resources and guidance to help them resolve the issue on their own.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary.memory.buffer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "3AdBv_MPkhe5",
        "outputId": "dbcba86b-c268-45bb-9879-906782e188bb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe human asked the AI what it was doing, and the AI responded that it was helping a customer with a technical issue. It was troubleshooting the issue and providing them with the best solution, as well as resources and guidance to help the customer resolve the issue on their own.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conversation Summary Buffer"
      ],
      "metadata": {
        "id": "n_HaQtss53XI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationSummaryBufferMemory"
      ],
      "metadata": {
        "id": "WBdM1nE3khcZ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "\n",
        "conversation_with_summary = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=ConversationSummaryBufferMemory(llm=OpenAI(), max_token_limit=40),\n",
        "    verbose=True,\n",
        ")\n",
        "conversation_with_summary.predict(input=\"Hi, what's up?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "OGaGhHEF5-N0",
        "outputId": "f7126210-cbf9-4064-e884-46839fa01572"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi, what's up?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hi there! I'm doing great. I'm currently helping a customer with a technical issue. How about you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Backed by a Vector Store"
      ],
      "metadata": {
        "id": "7er5iu4B63Nq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.memory import VectorStoreRetrieverMemory\n",
        "import faiss\n",
        "from langchain.docstore import InMemoryDocstore\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "\n",
        "embedding_size = 1536 # Dimensions of the OpenAIEmbeddings\n",
        "index = faiss.IndexFlatL2(embedding_size)\n",
        "embedding_fn = OpenAIEmbeddings().embed_query\n",
        "vectorstore = FAISS(embedding_fn, index, InMemoryDocstore({}), {})\n"
      ],
      "metadata": {
        "id": "aYHxz-VN627D"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In actual usage, you would set `k` to be a higher value, but i use k=1 to show that\n",
        "# the vector lookup still returns the semantically relevant information\n",
        "retriever = vectorstore.as_retriever(search_kwargs=dict(k=1))\n",
        "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
        "\n",
        "# When added to an agent, the memory object can save pertinent information from conversations or used tools\n",
        "memory.save_context({\"input\": \"My favorite food is pizza\"}, {\"output\": \"that's good to know\"})\n",
        "memory.save_context({\"input\": \"My favorite sport is soccer\"}, {\"output\": \"...\"})\n",
        "memory.save_context({\"input\": \"I don't the Celtics\"}, {\"output\": \"ok\"}) #"
      ],
      "metadata": {
        "id": "e0uSzw9H624c"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Notice the first result returned is the memory pertaining to tax help, which the language model deems more semantically relevant\n",
        "# to a 1099 than the other documents, despite them both containing numbers.\n",
        "print(memory.load_memory_variables({\"prompt\": \"what sport should i watch?\"})[\"history\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQ8mQCbU621n",
        "outputId": "77e11740-67ac-44d4-e898-d8913457b9d2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: My favorite sport is soccer\n",
            "output: ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs=dict(k=1))\n",
        "memory = VectorStoreRetrieverMemory(retriever=retriever)\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "_DEFAULT_TEMPLATE = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
        "\n",
        "Relevant pieces of previous conversation:\n",
        "{history}\n",
        "\n",
        "(You do not need to use these pieces of information if not relevant)\n",
        "\n",
        "Current conversation:\n",
        "Human: {input}\n",
        "AI:\"\"\"\n",
        "PROMPT = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"], template=_DEFAULT_TEMPLATE\n",
        ")\n",
        "conversation_with_summary = ConversationChain(\n",
        "    llm=llm,\n",
        "    prompt=PROMPT,\n",
        "    memory=memory,\n",
        "    verbose=True\n",
        ")\n",
        "conversation_with_summary.predict(input=\"Hi, my name is sekhar, what's up?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "2L4AvV_E62yN",
        "outputId": "563a3ced-74db-4968-bd8e-2a9c1e379c45"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Relevant pieces of previous conversation:\n",
            "input: Hi, my name is sekhar, what's up?\n",
            "response:  Hi Sekhar, nice to meet you. I'm doing well. How about you?\n",
            "\n",
            "(You do not need to use these pieces of information if not relevant)\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi, my name is sekhar, what's up?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hi Sekhar, nice to meet you. I'm doing well. How about you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_with_summary.predict(input=\"what's my favorite sport?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "RnOxxMKj8cT0",
        "outputId": "d841e49f-03e2-4c98-d5b6-e4933330ab09"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Relevant pieces of previous conversation:\n",
            "input: My favorite sport is soccer\n",
            "output: ...\n",
            "\n",
            "(You do not need to use these pieces of information if not relevant)\n",
            "\n",
            "Current conversation:\n",
            "Human: what's my favorite sport?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' You told me earlier that your favorite sport is soccer.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hHsOMB0n8cPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-e36RVie8cL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PbYqHJJE8cIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3uU99SsU62ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "30RRdf37W3ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chains\n",
        "\n",
        "Chains encode a sequence of calls to components like models, document retrievers, other Chains, etc."
      ],
      "metadata": {
        "id": "-HEjZLxnvg0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "llm = OpenAI()\n",
        "name = llm(\"I want to open a restaurant for indian food. suggest me a fancy name for this\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAevdhGAdWt7",
        "outputId": "e19c53ca-3f21-4bf2-f467-aa235ec63e2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Spice Bazaar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_template = PromptTemplate(\n",
        "    input_variables=['cuisine', 'location'],\n",
        "    template=\"I want to open a restaurant for {cuisine} food at {location}. suggest me a fancy name for it\"\n",
        ")\n",
        "\n",
        "my_chain = LLMChain(llm=llm,prompt=my_template, verbose=True)\n",
        "print(my_chain.predict(cuisine=\"india\", location=\"Vizag\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQR_f-jgdWrR",
        "outputId": "49658a25-b27a-4ba8-a003-fb66172e9972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for india food at Vizag. suggest me a fancy name for it\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "Mumbai Masala  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name_prompt = PromptTemplate(\n",
        "    input_variables=[\"cuisine\"],\n",
        "    template=\"I want to open a restaurant for {cuisine} food. suggest me a fancy name for it.\"\n",
        ")\n",
        "\n",
        "menu_prompt = PromptTemplate(\n",
        "    input_variables=['restaurant_name'],\n",
        "    template = \"suggest me some menu items for {restaurant_name}.\"\n",
        ")\n",
        "\n",
        "name_chain = LLMChain(llm = OpenAI(), prompt = name_prompt, verbose=True)\n",
        "menu_chain = LLMChain(llm = OpenAI(), prompt = menu_prompt, verbose = True)\n"
      ],
      "metadata": {
        "id": "2uPC-CyhdWkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "s_chain = SimpleSequentialChain(chains=[name_chain, menu_chain], verbose = True)\n",
        "print(s_chain(\"india\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCrxFY6K49sN",
        "outputId": "e79b56ae-29c0-4111-cc8f-78c3bfda98cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for india food. suggest me a fancy name for it.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "\n",
            "Maharaja's Palace Cuisine\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3msuggest me some menu items for \n",
            "\n",
            "Maharaja's Palace Cuisine.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "\n",
            "-Tandoori Chicken\n",
            "-Butter Chicken\n",
            "-Lamb Rogan Josh\n",
            "-Chicken Tikka Masala\n",
            "-Saag Paneer\n",
            "-Aloo Gobi\n",
            "-Matar Paneer\n",
            "-Korma\n",
            "-Palak Paneer\n",
            "-Kadai Paneer\n",
            "-Naan Bread\n",
            "-Raita\n",
            "-Mango Lassi\n",
            "-Gulab Jamun\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'india', 'output': '\\n\\n-Tandoori Chicken\\n-Butter Chicken\\n-Lamb Rogan Josh\\n-Chicken Tikka Masala\\n-Saag Paneer\\n-Aloo Gobi\\n-Matar Paneer\\n-Korma\\n-Palak Paneer\\n-Kadai Paneer\\n-Naan Bread\\n-Raita\\n-Mango Lassi\\n-Gulab Jamun'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "name_prompt = PromptTemplate(\n",
        "    input_variables=[\"cuisine\", \"location\"],\n",
        "    template=\"I want to open a restaurant for {cuisine} food at {location}. suggest me a fancy name for it.\"\n",
        ")\n",
        "\n",
        "menu_prompt = PromptTemplate(\n",
        "    input_variables=['restaurant_name'],\n",
        "    template = \"suggest me some menu items for {restaurant_name}.\"\n",
        ")\n",
        "\n",
        "name_chain = LLMChain(llm = OpenAI(), prompt = name_prompt, verbose=True, output_key=\"restaurant_name\")\n",
        "menu_chain = LLMChain(llm = OpenAI(), prompt = menu_prompt, verbose = True, output_key=\"menu_items\")\n",
        "\n",
        "my_restaurant = SequentialChain(chains=[name_chain, menu_chain],\n",
        "                                input_variables=['cuisine', 'location'],\n",
        "                                output_variables=['restaurant_name', 'menu_items'],\n",
        "                                verbose=True)\n",
        "\n",
        "\n",
        "print(my_restaurant({\"cuisine\":\"indian\", \"location\":\"Vizag\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpKgKkbp49p4",
        "outputId": "cfc166d2-ff4e-4c8c-d9e2-6a428691f32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for indian food at Vizag. suggest me a fancy name for it.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3msuggest me some menu items for \n",
            "\n",
            "Maharajah's Tandoori Delight.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'cuisine': 'indian', 'location': 'Vizag', 'restaurant_name': \"\\n\\nMaharajah's Tandoori Delight\", 'menu_items': '\\n\\n-Tandoori Chicken\\n-Naan\\n-Chicken Tikka Masala\\n-Lamb Rogan Josh\\n-Butter Chicken\\n-Vegetable Korma\\n-Spicy Potato Curry\\n-Chana Masala\\n-Biryani\\n-Saag Paneer\\n-Mango Lassi\\n-Gulab Jamun'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0S5MgOpJ49na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QmJX8HYQ49k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zgs1qyq149iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id=\"bigscience/bloom-1b7\",\n",
        "    task=\"text-generation\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "25897d15061d4b558b0197c07dba37dd",
            "e5b2d21bd1174eacbad4a2ccca2e6cd7",
            "6452a9c2e09a40feac0971095e95e250",
            "f7d022ec0a164d848c0ec8a7a6cf019d",
            "7dd521616bae4d0bad77727c04b6a96f",
            "5147156d06464b0d91782a5d51dfc7f5",
            "84e070e8ab3a4944b2f619ab80255041",
            "58fa7ede80ca47f591b38ccc246abd2d",
            "6821f430a9c54e13b61a2573226d2b57",
            "4540070d5bae4c7ea22e0bf134c5a0e2",
            "1a9caae9b24c4a5c839b2fe44df8f75d",
            "e98318f040c3486cbbcf67460ddcddfb",
            "a993cbd076a5443faf9a157f036d2ba9",
            "a7f2d5c0b80540b8a15af42eef0548a0",
            "13b205452af649b78b2291e940ed8b21",
            "97f21270e9d943718a430963a81149eb",
            "256ccb3625d445e4b665465e0f547270",
            "fa279731661249329626fa53d8265344",
            "2daeba0b4c644a56b6613b78ba63f09f",
            "213bef9e7c1045709a01228ac0a91561",
            "7fa411c2d2764942844bb35dd453f18f",
            "1b49bfb2a8dd4f018d26da288e0b566b",
            "05ee548345fc44f1bed53bdebab6cc8b",
            "eb79a9be5fcf4bf1a5c849bc938f3190",
            "c5ab20c19f0a4a1197c6609c66c4b5ea",
            "98fc6e206c2b472e9acfd581e2bd820a",
            "b7d7e08afc044812b4ce01efb2214dfb",
            "9d42b5dee89c4d3ab10e4307ae6277a5",
            "4cf4f15883924a08a731a43b1f509f37",
            "d759170d7c5343d98905cae418cdba07",
            "7260b4b5e0da48f180abd9a047c0dc12",
            "2e7ad7d90c2c4b81ba91dd3566f030d4",
            "df8854dbd4974160969c8b15990f33a1",
            "df721daaf54d48eeb107d0799606f07c",
            "2938ebc1fd04468b83d77a0540385d81",
            "c478eac246594169a483bf22df84b5a1",
            "ecd6a7cbc4c743999fdab5178ca23361",
            "2557e139501848e387d73106b9c66d74",
            "dd8d30441f4b42e894a20457b9c4cba9",
            "98f8bc6087e241fa815737acdec4d347",
            "ffb3dfb06cdb45c6894c2861ba5f8dca",
            "59c019a745994b1cb3bd0dd5ece90b6f",
            "908e051e80ae42deaf1901b2ed283a29",
            "38ee0d5f6074417681636697fa62a3b3",
            "020f59416b17415fb71872f505870e73",
            "34e4a67c852f4a60aae4b14d813a689e",
            "c4e4b11c0f994e65bde5c7524a444827",
            "87af62f61f4d499d967d9e5e650c3fb5",
            "4d393c87034341d59eb872cd4e97c439",
            "de75e37b9198410eb7f55c6a34c776da",
            "84198451569b4351a579ed94e7917d82",
            "c41e57bea367441f9b20d6a42b461b59",
            "1d78f74476814b85974fa3284384d8e2",
            "fda90a8c1c9f4e2997d05f88d8c1402a",
            "dd844f60b43e4d10a4150959dffd46af"
          ]
        },
        "id": "Yh21dWth49gN",
        "outputId": "21328c3e-71d9-4ecf-c5f1-8bf5cc1747dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/222 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25897d15061d4b558b0197c07dba37dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer.json:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e98318f040c3486cbbcf67460ddcddfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05ee548345fc44f1bed53bdebab6cc8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/715 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df721daaf54d48eeb107d0799606f07c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "020f59416b17415fb71872f505870e73"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"city\"],\n",
        "    template=\"Describe a perfect day in {city}?\",\n",
        ")\n",
        "llmchain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "llmchain.run(\"Paris\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "g17KIpp049dc",
        "outputId": "f6d79e2c-6dc5-48e0-d957-10af791cd092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' A day in Paris is a day that you will never forget'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name_prompt = PromptTemplate(\n",
        "    input_variables=[\"cuisine\", \"location\"],\n",
        "    template=\"I want to open a restaurant for {cuisine} food at {location}. suggest me a fancy name for it.\"\n",
        ")\n",
        "\n",
        "menu_prompt = PromptTemplate(\n",
        "    input_variables=['restaurant_name'],\n",
        "    template = \"suggest me some menu items for {restaurant_name}.\"\n",
        ")\n",
        "\n",
        "name_chain = LLMChain(llm = llm, prompt = name_prompt, verbose=True, output_key=\"restaurant_name\")\n",
        "menu_chain = LLMChain(llm = llm, prompt = menu_prompt, verbose = True, output_key=\"menu_items\")\n",
        "\n",
        "my_restaurant = SequentialChain(chains=[name_chain, menu_chain],\n",
        "                                input_variables=['cuisine', 'location'],\n",
        "                                output_variables=['restaurant_name', 'menu_items'],\n",
        "                                verbose=True)\n",
        "\n",
        "\n",
        "print(my_restaurant({\"cuisine\":\"indian\", \"location\":\"Vizag\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFKfH3aYctAX",
        "outputId": "74219039-058b-4cb0-f252-3e69e6508dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for indian food at Vizag. suggest me a fancy name for it.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 21, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3msuggest me some menu items for  I.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'cuisine': 'indian', 'location': 'Vizag', 'restaurant_name': ' I', 'menu_items': 'e. I want to show the menu items in'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "llm = HuggingFaceHub(repo_id=\"bigscience/bloom-1b7\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbvLC77fHqkG",
        "outputId": "862d9ea1-8f32-4cf0-979f-5e0e07eebc08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '0.19.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
            "  warnings.warn(warning_message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"city\"],\n",
        "    template=\"Describe a perfect day in {city}?\",\n",
        ")\n",
        "llmchain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "llmchain.run(\"Paris\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2ur2lUyhIBX7",
        "outputId": "0a8e3ee9-cdb2-4245-ea52-ee8f1f03bc89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' A day in Paris is a day that you will never forget'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name_prompt = PromptTemplate(\n",
        "    input_variables=[\"cuisine\", \"location\"],\n",
        "    template=\"I want to open a restaurant for {cuisine} food at {location}. suggest me a fancy name for it.\"\n",
        ")\n",
        "\n",
        "menu_prompt = PromptTemplate(\n",
        "    input_variables=['restaurant_name'],\n",
        "    template = \"suggest me some menu items for {restaurant_name}.\"\n",
        ")\n",
        "\n",
        "name_chain = LLMChain(llm = llm, prompt = name_prompt, verbose=True, output_key=\"restaurant_name\")\n",
        "menu_chain = LLMChain(llm = llm, prompt = menu_prompt, verbose = True, output_key=\"menu_items\")\n",
        "\n",
        "my_restaurant = SequentialChain(chains=[name_chain, menu_chain],\n",
        "                                input_variables=['cuisine', 'location'],\n",
        "                                output_variables=['restaurant_name', 'menu_items'],\n",
        "                                verbose=True)\n",
        "\n",
        "\n",
        "print(my_restaurant({\"cuisine\":\"indian\", \"location\":\"Vizag\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb6fZFyZIFLU",
        "outputId": "9c8e8992-c27c-4125-ea8b-3fc1a0e7ce36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for indian food at Vizag. suggest me a fancy name for it.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3msuggest me some menu items for  I.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'cuisine': 'indian', 'location': 'Vizag', 'restaurant_name': ' I', 'menu_items': 'e. I want to show the menu items in'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KadIZovZIVOO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}