{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX0xfUSykZYl"
      },
      "outputs": [],
      "source": [
        "# Installing packages\n",
        "\n",
        "!pip install langchain openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Prompt Template\n",
        "\n",
        "```markdown\n",
        "BasePromptTemplate --> PipelinePromptTemplate\n",
        "                       StringPromptTemplate --> PromptTemplate\n",
        "                                                FewShotPromptTemplate\n",
        "                                                FewShotPromptWithTemplates\n",
        "                       BaseChatPromptTemplate --> AutoGPTPrompt\n",
        "                                                  ChatPromptTemplate --> AgentScratchPadChatPromptTemplate\n",
        "\n",
        "\n",
        "\n",
        "BaseMessagePromptTemplate --> MessagesPlaceholder\n",
        "                              BaseStringMessagePromptTemplate --> ChatMessagePromptTemplate\n",
        "                                                                  HumanMessagePromptTemplate\n",
        "                                                                  AIMessagePromptTemplate\n",
        "                                                                  SystemMessagePromptTemplate\n",
        "\n",
        "PromptValue --> StringPromptValue\n",
        "                ChatPromptValue\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "vBRCS9TEkkq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PromptTemplate\n"
      ],
      "metadata": {
        "id": "sydFLfFFzuCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "from langchain.prompts.prompt import PromptTemplate"
      ],
      "metadata": {
        "id": "ox94CjEWk84n"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_template = PromptTemplate(\n",
        "    input_variables= ['cuisine'],\n",
        "    template=\"i want to open a {cuisine} restaurant. sugget me a good name\"\n",
        ")\n",
        "\n",
        "print(my_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JmBQ4d8nqpC",
        "outputId": "05bd7ff5-4761-4c03-9695-e328748af45f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['cuisine'] template='i want to open a {cuisine} restaurant. sugget me a good name'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PromptTemplate.format(my_template, cuisine=\"india\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Xh5k7nQNqouT",
        "outputId": "f0ae057c-5377-4725-99d8-bbcea975a387"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i want to open a india restaurant. sugget me a good name'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_template_2 = PromptTemplate(\n",
        "    input_variables= ['cuisine', 'location'],\n",
        "    template= \"i want to open a {cuisine} restaurant in {location}. suggest me a good name\"\n",
        ")\n",
        "print(PromptTemplate.format(my_template_2, cuisine=\"Mexican\", location=\"Vizag\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD7CVzVrrN67",
        "outputId": "b6ffa8dd-fd91-4680-a33a-cc44e509db48"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i want to open a Mexican restaurant in Vizag. suggest me a good name\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Au5V4Qwt0X8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FewShotPromptTemplate"
      ],
      "metadata": {
        "id": "idqXobbk0Yy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class langchain.prompts.few_shot.FewShotPromptTemplate\n",
        "\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate"
      ],
      "metadata": {
        "id": "aPraDQ2BvQ4f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [\n",
        "    {   \"question\": \"When was the founder of craigslist born?\",\n",
        "        \"answer\": \"December 6, 1952\"\n",
        "     },\n",
        "    {\n",
        "        \"question\": \"Who was the maternal grandfather of George Washington?\",\n",
        "        \"answer\": \"Joseph Ball\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"Are both the directors of Jaws and Casino Royale from the same country?\",\n",
        "        \"answer\": \"No\"\n",
        "    }\n",
        "]\n",
        "\n",
        "qa_template = PromptTemplate(\n",
        "    input_variables= [\"question\", \"answer\"],\n",
        "    template= \"Question: {question}\\nAnswer: {answer}\"\n",
        ")\n",
        "\n",
        "\n",
        "few_shot_template = FewShotPromptTemplate(\n",
        "    input_variables= [\"question\"],\n",
        "    example_prompt = qa_template,\n",
        "    prefix = \"please answer the following question based on these examples:\\n\\nQuestion: {question}\",\n",
        "    suffix = \"\\n\\nAnswer: \",\n",
        "    examples= examples\n",
        ")\n",
        "\n",
        "my_prompt = few_shot_template.format(question=\"who is the prime minister of india?\")\n",
        "\n",
        "print(my_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICBFT7gs0_hG",
        "outputId": "cd961bf6-fcd6-4e61-901a-1ebe83686322"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "please answer the following question based on these examples:\n",
            "\n",
            "Question: who is the prime minister of india?\n",
            "\n",
            "Question: When was the founder of craigslist born?\n",
            "Answer: December 6, 1952\n",
            "\n",
            "Question: Who was the maternal grandfather of George Washington?\n",
            "Answer: Joseph Ball\n",
            "\n",
            "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
            "Answer: No\n",
            "\n",
            "\n",
            "\n",
            "Answer: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langchain.llms import OpenAI\n",
        "from secret_key import openapi_key, serp_key, huggingface_key\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = openapi_key\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = huggingface_key"
      ],
      "metadata": {
        "id": "Lzi5eFx60_dd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(verbose=True)\n",
        "name = llm(my_prompt)\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHfzBrp20_ZJ",
        "outputId": "3a083636-d859-47eb-a4ee-f30d622e3886"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Narendra Modi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FXqx750N0_Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FewShotPromptWithTemplates\n",
        "\n",
        "I couldnt find much difference between the **FewShotPromptTemplates** and FewShotPromptWithTemplates if you found it just let me know or fork the branch and create a pull request i will merge it. Thank you."
      ],
      "metadata": {
        "id": "0nAn31uEUGys"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qhx677Qd0_L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoGPT"
      ],
      "metadata": {
        "id": "h1n5uB-sW0NN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Under Construction......!!!!!!!!!!!!\n"
      ],
      "metadata": {
        "id": "NH7_o2l9W3xe"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "30RRdf37W3ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chains\n",
        "\n",
        "Chains encode a sequence of calls to components like models, document retrievers, other Chains, etc."
      ],
      "metadata": {
        "id": "-HEjZLxnvg0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "llm = OpenAI()\n",
        "name = llm(\"I want to open a restaurant for indian food. suggest me a fancy name for this\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAevdhGAdWt7",
        "outputId": "e19c53ca-3f21-4bf2-f467-aa235ec63e2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Spice Bazaar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_template = PromptTemplate(\n",
        "    input_variables=['cuisine', 'location'],\n",
        "    template=\"I want to open a restaurant for {cuisine} food at {location}. suggest me a fancy name for it\"\n",
        ")\n",
        "\n",
        "my_chain = LLMChain(llm=llm,prompt=my_template, verbose=True)\n",
        "print(my_chain.predict(cuisine=\"india\", location=\"Vizag\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQR_f-jgdWrR",
        "outputId": "49658a25-b27a-4ba8-a003-fb66172e9972"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for india food at Vizag. suggest me a fancy name for it\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "Mumbai Masala  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name_prompt = PromptTemplate(\n",
        "    input_variables=[\"cuisine\"],\n",
        "    template=\"I want to open a restaurant for {cuisine} food. suggest me a fancy name for it.\"\n",
        ")\n",
        "\n",
        "menu_prompt = PromptTemplate(\n",
        "    input_variables=['restaurant_name'],\n",
        "    template = \"suggest me some menu items for {restaurant_name}.\"\n",
        ")\n",
        "\n",
        "name_chain = LLMChain(llm = OpenAI(), prompt = name_prompt, verbose=True)\n",
        "menu_chain = LLMChain(llm = OpenAI(), prompt = menu_prompt, verbose = True)\n"
      ],
      "metadata": {
        "id": "2uPC-CyhdWkC"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "s_chain = SimpleSequentialChain(chains=[name_chain, menu_chain], verbose = True)\n",
        "print(s_chain(\"india\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCrxFY6K49sN",
        "outputId": "e79b56ae-29c0-4111-cc8f-78c3bfda98cb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for india food. suggest me a fancy name for it.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3m\n",
            "\n",
            "Maharaja's Palace Cuisine\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3msuggest me some menu items for \n",
            "\n",
            "Maharaja's Palace Cuisine.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "\n",
            "-Tandoori Chicken\n",
            "-Butter Chicken\n",
            "-Lamb Rogan Josh\n",
            "-Chicken Tikka Masala\n",
            "-Saag Paneer\n",
            "-Aloo Gobi\n",
            "-Matar Paneer\n",
            "-Korma\n",
            "-Palak Paneer\n",
            "-Kadai Paneer\n",
            "-Naan Bread\n",
            "-Raita\n",
            "-Mango Lassi\n",
            "-Gulab Jamun\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'india', 'output': '\\n\\n-Tandoori Chicken\\n-Butter Chicken\\n-Lamb Rogan Josh\\n-Chicken Tikka Masala\\n-Saag Paneer\\n-Aloo Gobi\\n-Matar Paneer\\n-Korma\\n-Palak Paneer\\n-Kadai Paneer\\n-Naan Bread\\n-Raita\\n-Mango Lassi\\n-Gulab Jamun'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "name_prompt = PromptTemplate(\n",
        "    input_variables=[\"cuisine\", \"location\"],\n",
        "    template=\"I want to open a restaurant for {cuisine} food at {location}. suggest me a fancy name for it.\"\n",
        ")\n",
        "\n",
        "menu_prompt = PromptTemplate(\n",
        "    input_variables=['restaurant_name'],\n",
        "    template = \"suggest me some menu items for {restaurant_name}.\"\n",
        ")\n",
        "\n",
        "name_chain = LLMChain(llm = OpenAI(), prompt = name_prompt, verbose=True, output_key=\"restaurant_name\")\n",
        "menu_chain = LLMChain(llm = OpenAI(), prompt = menu_prompt, verbose = True, output_key=\"menu_items\")\n",
        "\n",
        "my_restaurant = SequentialChain(chains=[name_chain, menu_chain],\n",
        "                                input_variables=['cuisine', 'location'],\n",
        "                                output_variables=['restaurant_name', 'menu_items'],\n",
        "                                verbose=True)\n",
        "\n",
        "\n",
        "print(my_restaurant({\"cuisine\":\"indian\", \"location\":\"Vizag\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpKgKkbp49p4",
        "outputId": "cfc166d2-ff4e-4c8c-d9e2-6a428691f32c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for indian food at Vizag. suggest me a fancy name for it.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3msuggest me some menu items for \n",
            "\n",
            "Maharajah's Tandoori Delight.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'cuisine': 'indian', 'location': 'Vizag', 'restaurant_name': \"\\n\\nMaharajah's Tandoori Delight\", 'menu_items': '\\n\\n-Tandoori Chicken\\n-Naan\\n-Chicken Tikka Masala\\n-Lamb Rogan Josh\\n-Butter Chicken\\n-Vegetable Korma\\n-Spicy Potato Curry\\n-Chana Masala\\n-Biryani\\n-Saag Paneer\\n-Mango Lassi\\n-Gulab Jamun'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0S5MgOpJ49na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QmJX8HYQ49k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zgs1qyq149iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yh21dWth49gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g17KIpp049dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import HuggingFace\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"city\"],\n",
        "    template=\"Describe a perfect day in {city}?\",\n",
        ")\n",
        "\n",
        "llm = HuggingFace(\n",
        "    model_name=\"gpt-neo-2.7B\",\n",
        "    temperature=0.9\n",
        ")\n",
        "\n",
        "llmchain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "llmchain.run(\"Paris\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "xqkofmeYwoj7",
        "outputId": "54322073-8da1-4e55-d689-cc0e20b377af"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-b5779b672f2a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHuggingFace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchains\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m prompt = PromptTemplate(\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'HuggingFace' from 'langchain.llms' (/usr/local/lib/python3.10/dist-packages/langchain/llms/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oFKfH3aYctAX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}